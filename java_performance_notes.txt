##########################
# Chapter 1 = Introduction
##########################
- Performance considerations:
memory constraints
application speed

- need to check both:
Java programming language (20%)
JVM (80%)


#####################################################
# Chapter 2 = Just In Time Compilation and Code Cache
#####################################################

# What is bytecode?
Main.java => javac => Main.class => java Main

- javac command converts or compiles Main.java to bytecode - Main.class
- java command above is JVM which interprets and executes the bytecode
- same bytecode can run on any OS
- Java interpreter is different and more complex than traditional interpreters which goes line by line


# The concept of "Just In Time Compilation"
- JVM (java) has JIT compilation feature - whichever code block or method are hot and used more frequently,
JIT compiles that portion of code into native machine code which runs faster than bytecodes interpretation
- Thus, the code runs faster the longer it is left to run => also known as JVM warmup

- In JVM, there are multiple threads:
one thread is doing bytecode interpretation
another thread is doing JIT compilation
thus if more time is given for code run - all the native compilation would have been completed
and the code will execute faster


# Code example = performanceexample1 package
- run the PerformanceExample1Main class with Program arguments (not VM arguments) as 10
- or from command line: java PerformanceExample1Main 10


# Finding out which methods are getting compiled
- Compiler Flags: -XX:+PrintCompilation
- example:
java -XX:+PrintCompilation PerformanceExample1Main 5000

OR, run from IntelliJ Terminal
PerformanceExample1\target\classes>

java -XX:+PrintCompilation PerformanceExample1Main 5000
java -XX:+PrintCompilation PerformanceExample1Main 15000

- sample output:
...
...
    246   20  s    3       java.lang.StringBuffer::append (13 bytes)
    249   21       3       java.lang.String::<init> (82 bytes)
    249   22       3       java.lang.String::startsWith (7 bytes)
    250   23       3       java.util.HashMap::hash (20 bytes)
    251   24       1       java.util.ArrayList::size (5 bytes)
    251   25       3       java.lang.String::indexOf (70 bytes)
    251   26       3       java.util.HashMap::getNode (148 bytes)
    252   28     n 0       sun.misc.Unsafe::getObjectVolatile (native)
    252   29       3       java.lang.String::indexOf (7 bytes)
    252   27       3       java.util.concurrent.ConcurrentHashMap::tabAt (21 bytes)
    253   30       1       java.lang.Integer::intValue (5 bytes)
    253   31       1       java.lang.Boolean::booleanValue (5 bytes)
    253   32       3       com.rishi.PrimeNumbers::isPrime (35 bytes)
    253   34       3       java.lang.Number::<init> (5 bytes)
    254   35       3       java.lang.Integer::<init> (10 bytes)
    254   33       3       java.lang.Integer::valueOf (32 bytes)
    254   36       3       java.util.ArrayList::add (29 bytes)
    254   38 %     4       com.rishi.PrimeNumbers::isPrime @ 2 (35 bytes)
    255   37       3       java.util.ArrayList::ensureCapacityInternal (13 bytes)
...
...
    369   39       3       com.rishi.PrimeNumbers::getNextPrimeAbove (43 bytes)   made not entrant


- First column is the timer in ms, that it took to run and its cumulative. Last row is the total time.
- Second column is the order that the line item was run.
- Third column is blank or
n = native, s = synchronized
! would mean that some exception handling was going on
% would mean that the code has been natively compiled and is running in memory under the code cache.

- Fourth column has a value from 0 to 4. This corresponds as an ENUM to what type of compilation has taken place.
0: no compilation took place (code was interpreted)
1 through 4: is a range of compilation complexity (4 being greatest)

- Fifth and final column is the line item that was run.


# Compilers C1 & C2
There are two compilers in Java.
C1 handles Native compilation levels 1-3, while C2 handles native level 4 only
(which stores native compiles into the code cache).

The JVM determines the compilation level based on how often it is being run and
how complex or time consuming it is â€“ through profiling.

As there is a tradeoff in optimizing more complex code (higher native tier/levels),
it only will do this with methods that are called more often, or have greater complexity.


# Logging the compilation activity
java -XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation PerformanceExample1Main 5000

- creates a log file as : hotspot_pid11016.log


# Tuning the code cache size
- after logging the compilation activity, how can we use it to enhance performance
- native compiled code - level 4 by C2 compiler -> its placed in the code cache
- however, the code cache size is limited
- in a large application - where many methods can be compiled -> default code cache size may be insufficient

- warning may appear in logs:
VM warning: CodeCache is full. Compiler has been disabled.

- can print the code cache size: -XX:+PrintCodeCache
- example:
java -XX:+PrintCodeCache PerformanceExample1Main 5000

- sample output with Java 11:
CodeHeap 'non-profiled nmethods': size=120064Kb used=53Kb max_used=53Kb free=120010Kb
 bounds [0x000002ddf7c40000, 0x000002ddf7eb0000, 0x000002ddff180000]
CodeHeap 'profiled nmethods': size=120000Kb used=189Kb max_used=189Kb free=119810Kb
 bounds [0x000002ddf0710000, 0x000002ddf0980000, 0x000002ddf7c40000]
CodeHeap 'non-nmethods': size=5696Kb used=1033Kb max_used=1040Kb free=4663Kb
 bounds [0x000002ddf0180000, 0x000002ddf03f0000, 0x000002ddf0710000]
 total_blobs=474 nmethods=173 adapters=213
 compilation: enabled
              stopped_count=0, restarted_count=0
 full_count=0


- sample output with Java 8:
CodeCache: size=245760Kb used=1156Kb max_used=1168Kb free=244603Kb
 bounds [0x0000000002d70000, 0x0000000002fe0000, 0x0000000011d70000]
 total_blobs=300 nmethods=46 adapters=167
 compilation: enabled

size = around 20 MB
used = around 1 MB

- Java 8+ versions can have 240+ MB code cache size

- Change code cache size using 3 VM arguments:
InitialCodeCacheSize = code cache size when the app is started - normally around 160KB
ReservedCodeCacheSize = max code cache size possible
CodeCacheExpansionSize = how quickly the code cache should grow when initially full

- example:
Change the reserved code cache size to 28MB: -XX:ReservedCodeCacheSize=28m

- sample for Java 8
java -XX:ReservedCodeCacheSize=28m -XX:+PrintCodeCache PerformanceExample1Main 5000

- sample output
CodeCache: size=28672Kb used=1256Kb max_used=1268Kb free=27416Kb
 bounds [0x0000000003020000, 0x0000000003290000, 0x0000000004c20000]
 total_blobs=345 nmethods=82 adapters=176
 compilation: enabled


## Remote monitoring the code cache with JConsole
- launch JConsole:
C:\Program Files\Java\jdk-11.0.11\bin\jconsole.exe

- in order for jconsole to work, this folder should have write permissions:
C:\Users\rishi\AppData\Local\Temp\hsperfdata_rishi

- folder properties -> Security -> give Full Control or Modify permissions to Everyone
- now JConsole can be connected to a JVM and analyse memory code cache
- however, using JConsole decreases the performance of JVM as JVM has to do some extra work to communicate and provide data to JConsole
- thus the extra code cache size of around 2MB is used if using jconsole



################################
# Chapter 3 = Selecting the JVM
################################
- 2 compilers present = C1 (tier level 1-3), C2 (tier level 4)


## 32-bit
VM argument: -client
java -client Main 5000

- object pointers are 32-bit
- faster if heap < 3g
- Max heap = 4g
- C1 or client compiler only (tier 1-3)
- faster start up time
- runs for a shorter time as a client


## 64-bit
VM argument: -server
java -server Main 5000

- object pointers are 64-bit
- mandatory if heap > 4g
- Max heap = OS dependent
- faster if using long/double
- C1 or client compiler and C2 or server compiler (tier 4)
- runs for a longer time as a server

If OS is 32-bit, only can use
-client
-server

If OS is 64-bit, can use
-client
-server
-d64


## Turning off tiered compilation
- if only want to interpret the code, then use VM flag: -XX:-TieredCompilation
- only interpret and not compile !
- only use for very small application with few lines of code
- example:
java -XX:-TieredCompilation -XX:+PrintCompilation PerformanceExample1Main 5000


## Tuning native compilation within the JVM
# 2 main flags:
-XX:CICompilerCount=n
-XX:CompileThreshold=n

- code is only compiled when it is called n number of times

2 factors:
- no of threads involved in compilation
- threshold required for a method to run before its natively compiled and put in code cache
level 4 by C2


## to find no of threads used for compilation
- run this command: java -XX:+PrintFlagsFinal
- check for CICompilerCount
CICompilerCount = 3
so, 3 threads available for compilation

- another easier way to get threads
jinfo -flag CICompilerCount <pid>

sample output:
$ jinfo -flag CICompilerCount 13784
-XX:CICompilerCount=3

- increase threads and compile - doesn't make any difference if the code is small
java -XX:CICompilerCount=6 -XX:+PrintCompilation PerformanceExample1Main 15000

- default: atleast 2 threads for server JVM - for C1 and C2


## threshold
-XX:CompileThreshold=n

jinfo -flag CompileThreshold <pid>

- sample output
$ jinfo -flag CompileThreshold 13784
-XX:CompileThreshold=10000

- reduce the threshold
java -XX:CICompilerCount=6 -XX:CompileThreshold=1000 -XX:+PrintCompilation PerformanceExample1Main 15000

even worse performance


########################################################
# Chapter 4 - How memory works - the stack and the heap
########################################################

## how the stack works
- every thread has its own stack
- local variables are put in the executing thread stack
- local variables are removed from stack as soon as the scope ends
- always pass by value (copy)


## how the heap works
- objects created on heap, shared by all the threads
- reference to objects is stored in thread stack


## Happens-before

Happens-before relationship is a guarantee that action performed by one thread
is visible to another action in different thread.

If no happens-before, JIT compiler can reorder for optimization.

1. Single Thread rule
If a block of code is executed by a single thread, all the statements are executed in sequence.

2. Monitor Lock rule
An unlock on a monitor lock (exiting synchronized method/block) happens-before
every subsequent acquiring on the same monitor lock.

3. Volatile variable rule
A write to a volatile field happens-before every subsequent read of that same field.

Writes and reads of volatile fields have similar memory consistency effects as
entering and exiting monitors (synchronized block around reads and writes),
but without actually aquiring monitors/locks.

4. Thread start rule
A call to Thread.start() on a thread happens-before every action in the started thread.
Say thread A spawns a new thread B by calling threadA.start().
All actions performed in thread B's run method will see thread A's calling threadA.start() method and
before that (only in thread A) happened before them.

5. Thread join rule
All actions in a thread happen-before any other thread successfully returns from a join on that thread.
Say thread A spawns a new thread B by calling threadA.start() then calls threadA.join().
Thread A will wait at join() call until thread B's run method finishes.
After join method returns, all subsequent actions in thread A will see all actions performed in thread B's run method happened before them.


##############################################
# Chapter 5 - Passing Objects between methods
##############################################
- always pass by value
- final - helps for inlining by compilers
variable, method, class

- java doesn't support "const correctness"
example:
final Customer c = new Customer("Rishi");

c can not point to any other object in heap, however, Customer object's state can be changed

## Escaping references

1. class having map reference
if map is having getter, it can cause the breach in encapsulation if called clear()

- strategy 1 is to pass iterator instead of getter for map
however it will still have remove method to mutate the map

- strategy 2 - return the copy of map
small memory footprint, however not ideal solution

- strategy 3 - return the copy but as an immutable map
cannot mutate the map by the client too

Conclusion: for map field members, always return unmodifiable copy of map to client in getters

2. the map reference having mutable Object as value
- create copy constructor and return it in getter
so any changes in the returned copy will be not reflected to the original object

- or, return read only or immutable version of object => using interface and not providing setter
Return interface reference

- best way is to use modules in Java 9+ and only expose readonly implementations from the module









































######################
# Monitoring the Heap
######################

## Memory Leaks
- JVM releases all the objects or memory allocations back to OS once the programs finishes execution
- Soft leaks - when an object remains referenced when no longer needed

- demo: softleaks package
- change the VM arguments for CustomerHarness to be 10 MB using flag = -Xmx10m
- CustomerHarness program will crash due to out of memory


## JVisualVM
- jvisualvm.exe can be found in = C:\Program Files\Java\jdk1.8.0_172\bin
- however, if using JDK11, can be found and downloaded at:
https://visualvm.github.io/download.html

- run visualvm.exe
C:\Users\rishi\Downloads\visualvm_213\bin

- modify folder settings for full control security for everyone:
C:\Users\rishi\AppData\Local\Temp\hsperfdata_rishi

- for the first check, open Intellij (right click and Open)
- in the Monitor tab - we can monitor Heap

- rerun CustomerHarness program with 50MB heap
- fix the memory leak issue in code and the heap monitoring will look good - like small sharp mountains


## Heap Dump
- Generating a Heap Dump, 2 ways:
from JVisualVM - there is a button "Heap Dump"
from command line - pass parameters to jvm so that whenever app crashes with out of memory error - it will generate heap dump file .hprof

-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=<file path>

- visualize heap dump file using Memory Analyzer (MAT)
- download:
https://www.eclipse.org/mat
- once unzip - create a jre folder and copy jdk11 contents inside this folder

- in MAT, we can Acquire heap dump of a running process or open a heap dump file already present
- check Leak Suspect Reports


##################################
# Generational Garbage Collection
##################################

# "mark and sweep" process:
- mark:
collector checks what are the objects which needs to be retained
all the application threads are stopped
checks all the variables / statics / references on stack and referred objects on heap
- sweep:
all the objects in heap which are not marked are sweeped or deleted
move the live objects to contiguous memory (compact) to avoid memory fragmentation


# why generations
- to avoid gc pauses, better to divide the heap into generations as most objects don't live for long
- if an object survives it is likely to live forever
- GC will run faster if there are mostly garbage with very less live objects as the "marking" will complete quickly

- main generations: young and old
new objects are put in smaller young generation
as most of them are short-lived and theoretically garbage, GC will run and clean it quickly (minor collection)
surviving objects are moved to old generation - theoretically there will be fewer objects
once the threshold of old generation is also breached - GC will do major collection which is slow and time consuming


# young generation - more details
- divided into 3 regions: Eden, Survivor spaces: S0, S1
- new objects are first filled into Eden
- surviving objects are swapped to S0 or S1
- benefits: GC will scan only 2/3 of young generation: Eden + S0 or S1
- small drawback: 1/3 of young generation (S0 or S1) is not used
- once objects survive minor collections and being swapped in S0 or S1 for more than 5-6 times => it will be qualified to move to old generation


# viewing the generations in VisualVM
- need to install plugin
Tools -> Plugins -> Available Plugins -> install Visual GC
- once installed - new Visual GC tab will appear
- can run CustomerHarness program and see the Visual GC


#######################################
# Garbage Collector tuning & selection
#######################################

## Monitoring garbage collections
- options can be used: -verbose:gc
- create a Main class in softleaks package and run with VM arguments as: -Xmx10m -verbose:gc
- information in logs look like:
[3.692s][info][gc] GC(143) Pause Young (Normal) (G1 Evacuation Pause) 6M->1M(10M) 0.255ms

- means that minor collection ran and heap size before is 6M and new heap size after is 1M, total heap size is 10M and total gc time is 0.255 ms


## tuning off automated heap allocation sizing
- modify the Main class and rerun with 20MB heap
- check in VisualVM - VisualGC
- due to dynamic resizing - survivor spaces are made smaller and Eden space is larger
- old generation will keep in increasing slowly until the full GC will occur
- to disable dynamic sizing, use this flag: -XX:-UseAdaptiveSizePolicy
- to check the running process flag (run it from jdk/bin folder):
jinfo -flag UseAdaptiveSizePolicy <PID>

rishi@DESKTOP-6V79CIU MINGW64 /c/Program Files/Java/jdk-11.0.11/bin
$ ./jinfo.exe -flag UseAdaptiveSizePolicy 40368
-XX:+UseAdaptiveSizePolicy


## tuning garbage collection - old and young allocation
- always minor collection is better than major collection

a) flag to create the old generation vs young generation size: -XX:NewRatio=n
- if -XX:NewRatio=4 => it means old generation will be 4 times bigger than young generation

rishi@DESKTOP-6V79CIU MINGW64 /c/Program Files/Java/jdk-11.0.11/bin
$ ./jinfo.exe -flag NewRatio 37948
-XX:NewRatio=2

- default is 2 meaning old generation is 2 times bigger than young generation

- change new ratio to 1 so that young is equal to old:-Xmx20m -XX:NewRatio=1
$ ./jinfo.exe -flag NewRatio 23056
-XX:NewRatio=1

- from VisualVM - we can see that young = old

b) flag to create the survivor spaces (S0, S1) as compared to eden space size: -XX:SurvivorRatio=n

- default SurvivorRatio is 8 => it means that each of S0 and S1 will be 1/8th of the total young generation size
- thus 1/8 + 1/8 = 2/8 = 1/4th size of young generation => survivors space
- remaining 3/4th => Eden space

$ ./jinfo.exe -flag SurvivorRatio 23056
-XX:SurvivorRatio=8

- however, JVM may override this flag for maximum optimization

c) flag to specify how many minor collections should an object survive before promoted to old generation: -XX:MaxTenuringThreshold=n

- default MaxTenuringThreshold is 15 => means that object has to survive 15 minor collections before getting promoted to old generation
- 15 is the maximum number for this flag already

$ ./jinfo.exe -flag MaxTenuringThreshold 14716
-XX:MaxTenuringThreshold=15

- if any JVM allows higher value than 15 - like 16 or so... it means that object will never be promoted to old generation
- thus, its best to not tune this flag at all


################################
# Selecting a garbage collector
################################

# Types of collector:

a) Serial
- single thread for all garbage collection
- application and all application threads are paused
- use case: for background tasks where performance is not that important and other apps need more performance efficiency
- flag: -XX:+UseSerialGC

b) Parallel
- multiple threads doing minor collection
- flag: -XX:+UseParallelGC

c) Mostly Concurrent
- during marking phase only - multiple GC threads mark and application threads are stopped
- during sweeping phase - application threads are resumed
- flag for concurrent mark sweep: -XX:+UseConcMarkSweepGC
- flag for G1: -XX:+UseG1GC
- G1 is default collector from JDK10 onwards


#######################
# G1 Garbage Collector
#######################
- rerun the Main application with 20M heap size
- in VisualVM -> Visual GC => we can see that generations sizes and collections are very dynamic

# How G1 works?
- Heap is divided into equal sized regions like an excel spreadsheet - around 2048 by default
- Each cell can be randomly put as eden, survivors, old and there can be also unallocated regions
- minor collection: cleans all edens, survivors and reallocate regions
- full gc - check all the regions as old and clean those regions first which has most garbage
- entire old generation inspection may not be needed - just clean the most garbage old regions

# Tuning G1GC
- control number of GC threads: -XX:ConcGCThreads=n

- when to initiate G1 collection: -XX:InitiatingHeapOccupancyPercent=n
- default is 45% which means that when entire heap is 45% full, G1 will trigger
- this is different than other GC algorithms which depends on Eden space / old generation space to fill up

- String De-duplication: -XX:UseStringDeDuplication
- remove duplicate String objects from heap which are not in String pools



##########################################
# Using a profiler to analyse performance
##########################################

# Using a profiler
- Profiler will connect to running JVM and extract data information from it
- it means performance will be affected - so better to use only in DEV environment and not in PROD
- example profilers: JProfiler, YourKit which are very expensive
- open source: Java Mission Control (JMC)

# build JMC
- follow steps given in: https://github.com/openjdk/jmc#building-mission-control-from-source
git clone git@github.com:openjdk/jmc.git

# running the locally built jmc
"target\products\org.openjdk.jmc\win32\win32\x86_64\JDK Mission Control\jmc"

git bash:
target/products/org.openjdk.jmc/linux/gtk/x86_64/JDK\ Mission\ Control/jmc

cmd:
cd "C:\Users\rishi\ps\jmc\target\products\org.openjdk.jmc\win32\win32\x86_64\JDK Mission Control"

run command on cmd:
jmc -vm "C:\Program Files\Java\jdk-11.0.11\bin"

- the process to monitor can be expanded to se MBean Server (JMX Console) and Flight Recorder
- can customize Overview, MBean Browser, System tabs etc

# flight recorder
- record the state of the JVM through the course of the run
- start the application with VM arguments: -XX:+UnlockCommercialFeatures -XX:+FlightRecorder
- use JMC console to start the recording
- equivalent JVM argument: -XX:StartFlightRecording=delay=2min,duration=60s,name=Test,filename=recording.jfr,settings=profile

- analyse flight recorder dump


########################
# Assessing Performance
########################
- general idea is to get the start time and end time and get the duration
https://www.baeldung.com/java-measure-elapsed-time
- complications:
native compilation - will run code faster
garbage collection - will slow down

- Microbenchmark - measuring the performance of a small piece of code
- If run locally, more complications:
assessing in isolation
different hardware than production

- If we dont want to have native compilation (which is a bad idea), we can use this flag: -XX:-TieredCompilation
- JVM does native compilation for a method when its called many number of times => to enhance performance
- to check the native compilation happens or not from logs, use this flag => -XX:+PrintCompilation
- default compilation threshold is 10,000 - can reduce it to 1000 => -XX:CompileThreshold=1000


#########################
# Benchmarking with JMH
#########################
- install JMH
https://github.com/openjdk/jmh#preferred-usage-command-line











